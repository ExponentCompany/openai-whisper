{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Tranformers and datasets"
      ],
      "metadata": {
        "id": "c5g9NTF_Ixad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "w4VPaSlnHUvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClniiYCWHK4b"
      },
      "outputs": [],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load pre trained TF Whisper Tiny model"
      ],
      "metadata": {
        "id": "pljpioLsJOtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFWhisperModel, WhisperFeatureExtractor\n",
        "from datasets import load_dataset\n",
        "\n",
        "model = TFWhisperModel.from_pretrained(\"openai/whisper-tiny\")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "inputs = feature_extractor(\n",
        "    ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"tf\"\n",
        ")\n",
        "input_features = inputs.input_features\n",
        "decoder_input_ids = tf.convert_to_tensor([[1, 1]]) * model.config.decoder_start_token_id\n",
        "last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).last_hidden_state\n",
        "list(last_hidden_state.shape)"
      ],
      "metadata": {
        "id": "BJNOxn5vHaGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Saved momdel"
      ],
      "metadata": {
        "id": "W9XP25uhJl44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/tf_whisper_saved')"
      ],
      "metadata": {
        "id": "vpYwMmgyHf0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert saved model to TFLite model"
      ],
      "metadata": {
        "id": "TY_79jFEJYyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "saved_model_dir = '/content/tf_whisper_saved'\n",
        "tflite_model_path = 'whisper.tflite'\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "owez2zvzHl-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}